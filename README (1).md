# Founder Retention (Binary) & Multidimensional Personality Cluster Prediction (Multi-Class)  
Machine Learning Project (SVM + Neural Network)

---

## ðŸ“Œ Overview  
This project contains **two related ML tasks**:

### **1. Binary Classification â€” Founder Retention**
Predict whether a startup founder:  
- **Stayed** (1)  
- **Left** (0)

### **2. Multi-Class Classification â€” Multidimensional Personality Cluster Prediction**
Predict a **5-class personality cluster label** (e.g. `Cluster_A` â€¦ `Cluster_E`)  
based on behavioral, lifestyle, and psychometric features.

For both tasks, we use:

- **Multi-Layer Perceptron (Neural Network)**
- **Support Vector Machine (SVM)**

âž¡ï¸ In **both** binary and multi-class problems, the **Neural Network consistently outperformed SVM**.

---

# ðŸ”§ 1. Data Preprocessing Pipeline (Binary â€” Founder Retention)

All preprocessing is applied to both train and test (except label).  
Output CSVs for the binary task:

- `train_preprocessed_feature_engg.csv`
- `test_preprocessed_feature_engg.csv`

> The multi-class personality task uses an analogous preprocessing strategy  
> (scaling, encoding, and feature engineering on its own train/test files).

---

## 1.1 Feature Engineering (Founder Retention)

### âœ” Ordinal Encoding for Rating Columns
Converted rating-like textual fields into numeric levels (1â€“4 or 1â€“5):

- `work_life_balance_rating`
- `venture_satisfaction`
- `startup_performance_rating`
- `startup_reputation`
- `founder_visibility`
- `team_size_category`
- `startup_stage`
- `education_background`

Also created:
```text
<column>_ord_missing â†’ binary flag for missing ordinal values
```

---

### âœ” Founder Age Binning
```text
0â€“25 â†’ 0  
26â€“35 â†’ 1  
36â€“45 â†’ 2  
46â€“55 â†’ 3  
56+  â†’ 4
```

---

### âœ” Dependents & Family Features
- `has_dependents`
- `num_dependents_missing`
- `is_married`
- `is_single`

---

### âœ” Tenure & Startup Age
- `tenure_ratio`
- `tenure_gap`
- `years_since_founding_missing`

---

### âœ” Revenue Features
- `monthly_revenue_log`  
- `revenue_missing`
- `revenue_per_year_with_founder`
- `revenue_per_funding_round`

---

### âœ” Yes/No â†’ Binary Conversion
Added `_bin` columns for:

- `working_overtime`
- `remote_operations`
- `leadership_scope`
- `innovation_support`

---

### âœ” Interaction Features
- `remote_x_distance`
- `support_count`
- `satisfaction_minus_perf`
- `reputation_x_visibility`

---

## 1.2 Additional Preprocessing

### âœ” Global Missingness Indicators
```text
<column>_was_missing â†’ 1 if value was missing
```

---

### âœ” Rare Category Grouping
For all categorical columns:  
Categories representing **<1%** of the data are replaced with `"Other"`.

---

### âœ” Outlier Clipping (IQR method)
For each numeric feature:
```text
clip to [Q1 â€“ 3Â·IQR,  Q3 + 3Â·IQR]
```

---

### âœ” Log Transforms
Applied to skewed fields when present:
- `distance_from_investor_hub_log`
- `years_since_founding_log`

---

## 1.3 ColumnTransformer

Numeric Pipeline:  
- Median imputation  
- Standard scaling  

Categorical Pipeline:  
- Most frequent imputation  
- OneHotEncoder  

The final design matrix is saved to the preprocessed CSVs listed above.

---

# ðŸ¤– 2. Models â€” Binary Founder Retention

After preprocessing, identical datasets are used for both SVM and NN.

---

## ðŸ”· 2.1 Support Vector Machine (Binary)

### Model:
```python
SVC(kernel="rbf", C=1.0, gamma="scale")
```

### Pipeline:
1. Load preprocessed train/test
2. Stratified 80/20 split
3. Train SVM classifier
4. Validate on validation split
5. Retrain on full training data
6. Predict on test
7. Convert:
   - 0 â†’ Left  
   - 1 â†’ Stayed  
8. Save submission

### Performance:
- **Reasonable**, but **significantly lower** than the Neural Network model.

---

## ðŸ”· 2.2 Neural Network (Binary)

### Architecture:
```text
Input
 â†’ Linear(256) â†’ ReLU â†’ Dropout(0.3)
 â†’ Linear(128) â†’ ReLU â†’ Dropout(0.3)
 â†’ Linear(1)   â†’ BCEWithLogitsLoss
```

### Training Details:
- Loss: `BCEWithLogitsLoss` with **pos_weight** to handle class imbalance  
- Optimizer: Adam (lr = 1e-3)  
- Scheduler: ReduceLROnPlateau  
- Early stopping (patience = 8)  
- Stratified train/validation split  

### Output:
```text
sigmoid(logits) >= 0.5 â†’ {0,1}
```

### Result:
ðŸ‘‰ **Neural Network achieved higher validation accuracy and better generalization**  
than SVM for the founder retention task.

---

# ðŸŽ¯ 3. Multidimensional Personality Cluster Prediction (Multi-Class)

A separate dataset is used for this task, with:

- Feature columns representing **behavioral, lifestyle, and psychometric scores**
- Target column: `personality_cluster` with **5 classes**  
  (e.g. `Cluster_A`, `Cluster_B`, `Cluster_C`, `Cluster_D`, `Cluster_E`)

Preprocessing is analogous:
- Basic feature engineering for numerical / rating-style inputs  
- Scaling of numeric features  
- Encoding of categorical attributes  
- Train/validation split for model evaluation  

---

## ðŸ”· 3.1 SVM (Multi-Class)

Using the same RBF kernel SVM in multi-class mode:

```python
SVC(kernel="rbf", C=1.0, gamma="scale", decision_function_shape="ovr")
```

- Trained on preprocessed personality features  
- Predicts a label in `{Cluster_A, â€¦, Cluster_E}`  

---

## ðŸ”· 3.2 Neural Network (Multi-Class)

### Modified Architecture:
```text
Input
 â†’ Linear(256) â†’ ReLU â†’ Dropout
 â†’ Linear(128) â†’ ReLU â†’ Dropout
 â†’ Linear(5)   â†’ CrossEntropyLoss
```

### Training:
- Loss: `CrossEntropyLoss`  
- Optimizer: Adam  
- Early stopping strategy similar to binary case  

### Prediction:
```text
argmax(logits, dim=1) â†’ class index â†’ mapped to Cluster_A â€¦ Cluster_E
```

### Result:
ðŸ‘‰ **Neural Network outperformed SVM on the personality cluster prediction task**  
with higher overall accuracy and better class-wise performance.

---

# ðŸ Summary

| Task                                      | Model           | Performance      |
|-------------------------------------------|-----------------|------------------|
| Founder Retention (Binary)               | **Neural Net**  | â­ Best           |
| Founder Retention (Binary)               | SVM             | Good but weaker  |
| Personality Cluster (5-Class, Multi-Class)| **Neural Net**  | â­ Best           |
| Personality Cluster (5-Class, Multi-Class)| SVM             | Lower accuracy   |

---

# ðŸ“¦ Files (Binary Task)

| File                                 | Description                               |
|--------------------------------------|-------------------------------------------|
| `train_preprocessed_feature_engg.csv`| Full processed training features          |
| `test_preprocessed_feature_engg.csv` | Full processed test features              |
| `predictions_gpu_nn.csv`            | Binary NN predictions (retention)         |
| `predictions.csv`                   | Binary SVM predictions (retention)        |

> For the multi-class personality dataset, analogous preprocessed train/test  
> and predictions files are generated (with dataset-specific filenames).

---

# ðŸš€ Final Note  

The pipelines are fully modular and can be extended with:

- Gradient boosting models (XGBoost, LightGBM, CatBoost)  
- Ensembling (stacking / blending NN + tree models)  
- SHAP-based interpretability  
- Hyperparameter tuning (GridSearch / Optuna / Bayesian optimization)

Feel free to plug in additional models on top of the preprocessed data.
